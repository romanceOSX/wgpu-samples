--> https://www.w3.org/TR/webgpu/
--> https://sotrh.github.io/learn-wgpu/#what-is-wgpu

instance
surface
adapter
(device, queue)
surface


Webgpu spec
    --> 3.5
Adapters (instances?) of type 'GpuAdapters'
    GpuAdapters expose Adapters
    Calling GpuAdapters::reques_device creates a
    device

    A device is a logical instantiation of an adapter


Adapters represent an implementation of Webgpu
You get the actual devices through the adapters

Programming model
    Operations are are available at speciifc timeline's states

Textures and texture views
    1/2/3-D arrays of data, which can contain multiple values per element to represent
    things like colour
    They can be used in many ways (determined by the GPUTextureUsage) such as:
        - sampled/read/written by a compute/graphics pipeline shaders
        - written by render pass outputs
    They are stored within GPU memory

    A single texture consists of one or more texture subresources

    Workflow
        Load the image
        Create a texture to holds the image's data
        Load the bytes into the texture (CPU to GPU op done through the queue)
        Create a Texture View to access the texture and a Sampler to retrieve the data

    Texture view
        It is a view into the texture resource, since the same texture resource can
        be used differently in different places the view grants this access
    
    Textures -> the physical resource
    Texture view -> what am I sampling?
    Sampler -> how am I sampling it?


Bind group
    It describes a set of resources that can be accessed by a shader
    Bind group layout, describes how the resource will be used
    Bind group tells what is the resource
    It is separated so we can change the bind group on the fly

    Map:
        ```
        Pipeline Layout <=> Bind Group Layout <=> Bind Group <=> Texture View
        ```

Pipeline Layout
    This contains a list of bindgroup layouts to use

Shaders
    --> https://www.w3.org/TR/WGSL/
    The following shaders are supported
        - vertex
        - fragment
        - compute
    
    Vertices are then converted to fragments where one pixel gets at least one
    fragment

    The fragment shader decides the output color

    WGSL is designed to be easily converted into the the different back-ends shading
    language, this is done through the 'naga' crate in wgpu

clip coordinates
    --> https://en.wikipedia.org/wiki/Clip_coordinates
    
Buffers
    - vertex
        VertexBufferLayout
            describes how the data is laid out in memory so it can correctly be
            interpreted by the shader
            Equivalent of input attribute bindings and descriptors in vulkan
    - index
        This is a 'store' of vertices, where we can reference those vertex by index
        later in the pipeline, working with 'references' allow for shallow copies
        which helps with duplicated/overlaping vertices

General Pipeline workflows:
    We define layouts, layouts describe how the pipeline will use the resources (extremely oversimplified)
    Through the encoder (command buffer) we specify the concrete resources (non-layout) at runtime

Comparision
    BindGroupLayout     | Resource types
    PipelineLayout      | Declares resources' interface
    Bind Group          | Actual Resources

Concepts:
    - pipeline
    - pipeline layout
    - textures
    - color attachments
    - Vertex Buffers
        - Vertex Buffers layout
    - Shader modules

    All of these are set through command buffers
        render_pass(Pipeline) <=> layout's <=> resources
        render_pass(Pipeline) <=> Pipeline Layout <=>  Bind Group Layout <=> Bind Group <=> Texture View <=> Texture
        render_pass(Pipeline) <=> VertexBufferLayout <=> VertexBuffer
        render_pass(Pipeline) <=>  <=> IndexBuffer

NOTES:
    There is no such thing as an index buffer layout, since indexes are just that, indexes... there is
    no need to create a layout to describe them

